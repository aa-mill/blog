{"posts":[{"title":"Active vs. Passive Transformations","text":"IntroductionI always pause on statements like $O \\to D(g)OD(g)^{\\dagger}$ because I get stuck trying to reason about what transformation is actually going on. It’d be nice to look at the placement of the $\\dagger$ and have a clear sense of this, so my goal here is to separate two different sets of ideas: Active vs. passive transformations, and Transformations vs. a change of basis. The distinctions can but subtle, and many texts don’t explicitly specify the convention they’re using. It’s also my opinion that these notions are less symmetric than many sources make them out to be. Active transformationsLet $Q$ be some quantum mechanical operator, and let $U$ be some unitary transformation. In an active transformation, we transform the states but not the operators, i.e. $$\\begin{align}| \\psi \\rangle &amp;\\to U| \\psi \\rangle, \\\\\\langle \\psi | &amp;\\to \\langle \\psi |U^{\\dagger}, \\\\Q &amp;\\to Q.\\end{align}$$ That is, we’re actually changing the system. As a result, the expectation value of $Q$ changes as $\\langle \\psi | Q | \\psi \\rangle\\to \\langle \\psi | U^{\\dagger}QU | \\psi \\rangle$. Nothing says that these two expectation values have to be equal. After all, the state is different, so it makes sense that we could measure different values for the observable corresponding to $Q$. Note that I didn’t need to say anything about matrix elements or vector components to define an active transformation. However, if we do want to talk about these things, we can start by asking what the matrix elements of $Q$ look like. The matrix elements always depend on our choice of basis, so if we choose our basis vectors to be the transformed vectors (i.e. the images of $U$), then the matrix elements of $Q$ become $$\\begin{pmatrix}\\langle e_{1} | Q | e_{1} \\rangle &amp; \\langle e_{1} | Q | e_{2} \\rangle &amp; \\cdots \\\\\\langle e_{2} | Q | e_{1} \\rangle &amp; \\langle e_{2} | Q | e_{2} \\rangle &amp; \\\\\\vdots &amp; &amp; \\ddots\\end{pmatrix}\\begin{pmatrix}\\langle e_{1} | \\psi \\rangle \\\\\\langle e_{2} | \\psi \\rangle \\\\\\vdots\\end{pmatrix}\\to \\begin{pmatrix}\\langle e_{1} | U^{\\dagger}QU | e_{1} \\rangle &amp; \\langle e_{1} | U^{\\dagger}QU | e_{2} \\rangle &amp; \\cdots \\\\\\langle e_{2} | U^{\\dagger}QU | e_{1} \\rangle &amp; \\langle e_{2} | U^{\\dagger}QU | e_{2} \\rangle &amp; \\\\\\vdots &amp; &amp; \\ddots\\end{pmatrix}\\begin{pmatrix}\\langle e_{1}| \\psi \\rangle \\\\\\langle e_{2}| \\psi \\rangle \\\\\\vdots\\end{pmatrix}.$$ Passive transformationsIn a passive transformation, we transform the operators but not the states. We can obtain the same change in expectation values as before, namely $\\langle \\psi | Q | \\psi \\rangle\\to \\langle \\psi | U^{\\dagger}QU | \\psi \\rangle$, if we let $$\\begin{align}| \\psi \\rangle &amp;\\to | \\psi \\rangle , \\\\\\langle \\psi | &amp;\\to \\langle \\psi |, \\\\Q &amp;\\to U^{\\dagger}QU.\\end{align}$$ In other words, we let the operator transform such that the expectation value of the original operator for the transformed state is the same as that of the transformed operator on the original state. What I’ve said so far is summarized succinctly in this comment. TransformationsThe key idea I want to emphasize is that, for both conventions, what I’ve so far described is a transformation of the system that changes the physics. That is, in general, it will be that $\\langle \\psi | Q | \\psi \\rangle \\neq \\langle \\psi | U^{\\dagger}QU | \\psi \\rangle$. Change of basisOn the other hand, with a change of basis, transforming either the states or the operator must come with a compensatory change in the other so that the physics do not change. In particular, if we actively transform the states via $| \\psi \\rangle\\to | \\psi’ \\rangle = U| \\psi \\rangle$, then the operator $Q$ must also transform, namely as $Q\\to Q’ = UQU^{\\dagger}$, such that $$\\langle \\psi’ | Q’ | \\psi’ \\rangle = \\langle \\psi | U^{\\dagger}(UQU^{\\dagger})U | \\psi \\rangle = \\langle \\psi | Q | \\psi \\rangle.$$ The difference between a transformation and a change of basis thus alleviates the confusion when encountering an excerpt such as “the states transform as $| \\psi \\rangle\\to D(g)| \\psi \\rangle$, so the operators transform as $O \\to D(g)OD(g)^{\\dagger}$.” Here, since the states and operators transform oppositely, the transformation is indicating a change of basis. Had the transformation been specified exclusively for the states (or exclusively for the operators), it’d indicate a transformation that changes the physics of the system. The last thing I’ll add is a short rule for the placement of the $\\dagger$. In a change of basis, the operator that acts on the states is the leftmost operator in the operator transformation. In a transformation, it’s the rightmost operator.","link":"/blog/2025/02/25/actvspas/"},{"title":"Angular Momentum and Rotations in Quantum Mechanics","text":"SummaryI wrote this post for two reasons: Quantum mechanics is cool and extremely fun to learn/write about. If you’re planning on understanding or doing research on equivariant neural networks, you’re going to encounter the Clebsch-Gordon tensor product, which is a way to combine objects known as spherical tensors. In my experience, it helps immensely to conceptualize this mechanism in terms of the addition of angular momentum eigenstates. I want to first outline the context from quantum mechanics necessary to do this, and I’ll make the connection in another post. The background here closely follows the following texts: Sakurai, J.J., Napolitano, J., 2021. Modern quantum mechanics, 3rd ed. ed. Cambridge University Press, Cambridge. (referred to here as Sakurai) Griffiths, D.J., Schroeter, D.F., 2018. Introduction to quantum mechanics, Third edition. ed. Cambridge University Press, Cambridge ; New York, NY. (referred to here as Griffiths) Classical motivationThe basic properties of rotations in quantum mechanics stem from the commutation relations obeyed by the angular momentum operators. Before unpacking this, we can get a sense of when and how rotations fail to commute by considering rotations in classical physics. I’ll say the connection between rotations and angular momentum shortly. Imagine a vector $\\boldsymbol{V}$ in three dimensions with components $V_{x}$, $V_{y}$, and $V_{z}$ in an orthogonal coordinate system: $$\\boldsymbol{V} = \\begin{pmatrix}V_{x} \\\\V_{y} \\\\V_{z}\\end{pmatrix}.$$ Suppose we rotate this vector. We can describe the rotation with an orthogonal matrix $R\\in \\mathbb{R}^{3\\times 3}$ that specifies how its components change under the rotation. For example, the matrix describing a rotation by angle $\\phi$ around the $z$-axis is $$R_{z}(\\phi) = \\begin{pmatrix}\\cos\\phi &amp; -\\sin\\phi &amp; 0 \\\\\\sin \\phi &amp; \\cos \\phi &amp; 0 \\\\0 &amp; 0 &amp; 1\\end{pmatrix}.$$ (The general form of $R$ for arbitrary rotations is given by Rodrigues’ rotation formula, which can be derived by considering how the components of $\\boldsymbol{V}$ parallel and perpendicular to the axis of rotation change.) It’s worth pointing out early on that there’s a difference between “active” and “passive” rotations of a physical system (e.g. observe how I said “Suppose we rotate this vector” vs. “Suppose we rotate our coordinate system”). I didn’t fully appreciate this at first, but knowing the difference is extremely helpful later on when trying to understand the definition of a spherical tensor. I’ll hopefully write a post about this later, but for now I’ll just link these resources. Sakurai uses the active rotation convention that a positive $\\phi$ in the $R_{z}(\\phi)$ matrix corresponds to a counterclockwise rotation of the physical system (not the coordinate axes) in the $xy$-plane, as viewed from the positive $z$-axis. Anyway, writing the analogous matrices for $R_{x}(\\phi)$ and $R_{y}(\\phi)$ and considering $\\phi = \\varepsilon \\ll 1$, we can obtain $$R_{x}(\\varepsilon)R_{y}(\\varepsilon) - R_{y}(\\varepsilon)R_{x}(\\varepsilon) = R_{z}(\\varepsilon^{2}) - 1 \\tag{3.7 Sakurai}$$ to second order in $\\varepsilon$. This is the classical commutation relation between the matrices for rotations about the $x$- and $y$-axes, and it gives a quantitive description of how these rotations fail to commute (Note that if we considered only first order in $\\varepsilon$, the rotations would commute). We expect that an analogous relationship will exist in the quantum case. Defining rotations in quantum mechanicsWe just saw that a rotation matrix $R$ acts on the three components of a classical column vector in 3D space. In quantum mechanics, we work with kets whose dimensionality varies based on the space in question. For example, when considering only the spin degree of freedom for a spin $\\frac{1}{2}$ particle, the ket space is two-dimensional, and operators take the form of $2\\times 2$ matrices. So, to speak generally about a rotation identified with $R$, we associate an abstract rotation operator $\\mathscr{D}(R)$, which takes different matrix representations depending on the ket space. We construct $\\mathscr{D}(R)$ by analogy to the infinitesimal operators used to describe translation and time evolution (I don’t understand the origin of the infinitesimal forms yet, so I’m taking Sakurai’s word here. Nonetheless, given the forms, the construction-by-analogy is clear enough). The general form of the infinitesimal operators is $$U_{\\varepsilon} = 1 - iG\\varepsilon,$$ where $G$ (Hermitian) $\\varepsilon$ Translations $p_{x}/\\hbar$ $dx’$ Time evolution $H/\\hbar$ $dt$ Rotation $\\boldsymbol{J}\\cdot\\hat{\\boldsymbol{n}}/\\hbar$ $d\\phi$ The last line of the table introduces the angular momentum operator $\\boldsymbol{J}$, which is defined so that $$\\mathscr{D}(\\hat{\\boldsymbol{n}}, d\\phi) = 1 -i\\left( \\frac{\\boldsymbol{J}\\cdot\\hat{\\boldsymbol{n}}}{\\hbar}d\\phi \\right)$$ is the infinitesimal rotation operator. In other words, $\\boldsymbol{J}$ is defined to make the pattern in the last row of the table hold. Sometimes, for example in Griffiths, $\\boldsymbol{J}$ is defined as $\\boldsymbol{x}\\times \\boldsymbol{p}$. The method shown here is more general because it also applies to spin, which has no classical analogue. A finite rotation operator can be obtained from the infinitesimal operators as $$\\mathscr{D}(\\hat{\\boldsymbol{n}}, \\phi) = \\lim_{ N \\to \\infty } \\left[ 1 - i\\left( \\frac{\\boldsymbol{J}\\cdot \\hat{\\boldsymbol{n}}}{\\hbar} \\right)\\left( \\frac{\\phi}{N} \\right) \\right]^{N} = \\exp\\left( \\frac{-i\\boldsymbol{J}\\cdot \\hat{\\boldsymbol{n}}\\phi}{\\hbar} \\right), \\tag{3.16 Sakurai}$$ where we’ve used the identity $$\\lim_{ n \\to \\infty } \\left( 1 + \\frac{x}{n} \\right)^{n} = e^{x}.$$ Note that $\\mathscr{D}_{z}(\\phi)$, $\\mathscr{D}(\\hat{\\boldsymbol{n}}, \\phi)$, $\\mathscr{D}(\\alpha, \\beta, \\gamma)$, and $\\mathscr{D}(R)$ are all notations for the rotation operator; they’re just different shorthands for the different ways of specifying a rotation, which will hopefully become clear. To complete the definition of $\\mathscr{D}(R)$, we postulate that these operators inherit the group properties of $R$, i.e. we postulate that the mapping $\\mathscr{D}$ is a group homomorphism. In summary, to define $\\mathscr{D}(R)$, we Obtain its form the infinitesimal rotation operator Postulate that the finite rotation operators form a group From this definition, we can determine the angular momentum commutation relations, on which all the properties of rotations in quantum mechanics are based. Fundamental angular momentum commutation relationsWe can substitute the Taylor expansion of $\\mathscr{D}_{z}(\\varepsilon)$ into the classical commutation relation in Eq. 3.7 to obtain $[J_{x}, J_{y}] = i\\hbar J_{z}$. Repeating this pattern for the other coordinate directions gives $$[J_{i}, J_{j}] = i\\hbar\\varepsilon_{ijk}J_{k}, \\tag{3.20 Sakurai}$$ the fundamental commutation relations of angular momentum. One can use these to show that $$\\langle J_{k} \\rangle \\to \\sum_{l}R_{kl}\\langle J_{l} \\rangle,$$ i.e. the expectation values of the angular momentum components transform as the components of a classical vector under a rotation. So far, we have only conceptualized $\\boldsymbol{J}$ as the angular momentum operator for a single particle. However, it turns out that Eq. 3.20 also holds when $\\boldsymbol{J}$ is the total spin operator in a tensor product space, for example $\\boldsymbol{J} = \\boldsymbol{J}_{1}\\otimes 1 + 1\\otimes\\boldsymbol{J}_{2}$, where $\\boldsymbol{J}_{1}$ and $\\boldsymbol{J}_{2}$ are the angular momentum operators acting on two particles labeled 1 and 2, respectively. This holds because operators in different subspaces of a tensor product space commute. Ways of representing rotations1. $\\mathrm{SO}(3)$ languageThe set of $3\\times 3$ orthogonal matrices $R$ with $\\det R = 1$, along with the standard matrix multiplication operation, satisfies the group axioms and is called $\\mathrm{SO}(3)$. 2. $\\mathrm{SU}(2)$ languageIn the Pauli two-component formalism, we have $$\\exp\\left( \\frac{-i\\boldsymbol{S}\\cdot\\hat{\\boldsymbol{n}}\\phi}{\\hbar} \\right) \\doteq \\exp\\left( \\frac{-i\\boldsymbol{\\sigma}\\cdot\\hat{\\boldsymbol{n}}\\phi}{2} \\right),$$ The $\\doteq$ notation, which means “is represented by,” emphasizes the fact that the operator on the left acts on a ket, while its matrix representation on the right acts on a spinor. Explicitly, the matrix representation is $$e^{-i\\boldsymbol{\\sigma}\\cdot\\hat{\\boldsymbol{n}}\\phi/2} =\\begin{pmatrix}\\cos\\left( \\frac{\\phi}{2} \\right)-in_{z}\\sin\\left( \\frac{\\phi}{2} \\right) &amp; (-in_{x} - n_{y})\\sin\\left( \\frac{\\phi}{2} \\right) \\\\(-in_{x} + n_{y})\\sin\\left( \\frac{\\phi}{2} \\right) &amp; \\cos\\left( \\frac{\\phi}{2} \\right) + in_{z}\\sin\\left( \\frac{\\phi}{2} \\right)\\end{pmatrix}, \\tag{3.63 Sakurai}$$ which has the form $$U(a, b) = \\begin{pmatrix}a &amp; b \\\\-b^{*} &amp; a^{*}\\end{pmatrix},$$ with $|a|^{2} + |b|^{2} = 1$, of a general unitary matrix. The set of unitary unimodular matrices (unitary matrices $U$ with $\\det(U) = 1$), along with the standard matrix multiplication operation, forms the group $\\mathrm{SU}(2)$. Matrix representationsThe matrix elements of the rotation operator (Eq. 3.16), given by $$\\mathscr{D}_{m’m}^{(j)}(R) = \\langle j\\ m’ | \\exp\\left( \\frac{-i\\boldsymbol{J}\\cdot\\hat{\\boldsymbol{n}}\\phi}{\\hbar} \\right) | j\\ m \\rangle \\tag{3.194 Sakurai}$$ or $$\\mathscr{D}_{m’m}^{(j)}(\\alpha, \\beta, \\gamma) = \\langle j\\ m’ | \\exp\\left( \\frac{-iJ_{z}\\alpha}{\\hbar} \\right)\\exp\\left( \\frac{-iJ_{y}\\beta}{\\hbar} \\right)\\exp\\left( \\frac{-iJ_{z}\\gamma}{\\hbar} \\right) | j\\ m \\rangle,$$ are called Wigner functions. The former equation is relevant if $R$ is specified by $\\hat{\\boldsymbol{n}}$ and $\\phi$. The latter is relevant if $R$ is expressed with Euler angles, in which case we can further write $$\\mathscr{D}_{m’m}^{(j)}(\\alpha, \\beta, \\gamma) = e^{-i(m’\\alpha + m\\gamma)}d_{m’m}^{(j)}(\\beta),$$ where $$d_{m’m}^{(j)}(\\beta) \\equiv \\langle {j\\ m’} | \\exp\\left( \\frac{-iJ_{y}\\beta}{\\hbar} \\right) | j\\ m \\rangle.$$ Note that since $\\boldsymbol{J}^{2}$ and $J_{k}$ commute, so do $\\boldsymbol{J}^{2}$ and $\\mathscr{D}(R)$, and hence $\\mathscr{D}(R)| j\\ m \\rangle$ is an eigenket of $\\boldsymbol{J}^{2}$ with the same eigenvalue. It follows that $\\langle j’\\ m’ | \\mathscr{D}(R) | j\\ m \\rangle = 0$ unless $j’ = j$, which is why $\\mathscr{D}_{m’m}^{(j)}(R)$ is defined for a single $j$. The $(2j + 1)\\times(2j + 1)$ matrix formed from these elements is the $(2j + 1)$-dimensional irreducible representation of the rotation operator. These matrices form a group: Identity: $\\phi = 0$. Inverse: $\\phi \\to -\\phi$. Note that $\\mathscr{D}(R)$ is unitary, so $\\mathscr{D}_{m’m}(R^{-1}) = \\mathscr{D}_{mm’}^{*}(R)$. Closure: Consider $$ \\begin{align} \\mathscr{D}(R_{1})\\mathscr{D}(R_{2}) &amp;= \\mathscr{D}(R_{1}R_{2}), \\\\ \\sum_{m’}\\mathscr{D}(R_{1})| j\\ m’ \\rangle\\langle j\\ m’ | \\mathscr{D}(R_{2}) &amp;= \\mathscr{D}(R_{1}R_{2}), \\\\ \\sum_{m’}\\langle j\\ m’’ |\\mathscr{D}(R_{1})| j\\ m’ \\rangle\\langle j\\ m’ |\\mathscr{D}(R_{2})| j\\ m \\rangle &amp;= \\langle j\\ m’’ | \\mathscr{D}(R_{1}R_{2}) | j\\ m \\rangle, \\\\ \\sum_{m’}\\mathscr{D}_{m’’m’}^{(j)}(R_{1})\\mathscr{D}_{m’m}^{(j)}(R_{2}) &amp;= \\mathscr{D}_{m’’m}^{(j)}(R_{1}R_{2}). \\end{align} $$ The first line follows from the postulate that the rotation operators are a group. Next, we insert the identity operator (We could have also summed over $j$ here, but since the matrix elements of $\\mathscr{D}(R)$ vanish for states with different $j$, the sum would go away in the next step). Finally, we insert each side of the equation between $\\langle j\\ m’’ |$ and $| j\\ m \\rangle$. Associativity: Follows from rules of matrix multiplication. Eigenvalues and eigenstatesImportant operators: $\\boldsymbol{J}^{2} \\equiv J_{x}J_{x} + J_{y}J_{y} + J_{z}J_{z}$ $J_{\\pm} \\equiv J_{x} \\pm iJ_{y}$ (non-Hermitian) $J_{\\pm}J_{\\mp} = \\boldsymbol{J}^{2} - J_{z}^{2} \\pm \\hbar J_{z}$ Note $J_{+}^{\\dagger} = J_{-}$, so, e.g., $J_{+}^{\\dagger}J_{+} = \\boldsymbol{J}^{2}-J_{z}^{2}+\\hbar J_{z}$. Important commutation relations $[\\boldsymbol{J}^{2}, J_{k}] = 0$ $[J_{+}, J_{-}] = 2\\hbar J_{z}$ $[J_{z}, J_{\\pm}] = \\pm \\hbar J_{pm}$ $[\\boldsymbol{J}^{2}, J_{\\pm}] = 0$ Using only the fundamental angular momentum commutation relations, one can show that (see Sakurai §3.5 or Griffiths §4.3) We can choose one of $J_{x}$, $J_{y}$, and $J_{z}$ to be simultaneously diagonalized with $\\boldsymbol{J}^{2}$. The $J_{+}$ ($J_{-}$) operator raises (lowers) the eigenvalue of an eigenstate of $J_{z}$ by one unit of $\\hbar$ but leaves the eigenvalues of $\\boldsymbol{J}^{2}$ unchanged. The eigenvalue relationships for $\\boldsymbol{J}^{2}$ and $J_{z}$ are $$ \\boldsymbol{J}^{2}| j\\ m \\rangle = j(j + 1)\\hbar^{2}| j\\ m \\rangle\\quad\\text{and}\\quad J_{z}| j\\ m \\rangle = m\\hbar | j\\ m \\rangle, $$ where $j = 0, \\frac{1}{2}, 1, \\frac{3}{2}, \\dots$ and $m = -j, -j + 1, \\dots, j - 1, j$. Using the fact that $J_{\\pm}| j\\ m \\rangle = c_{jm}^{\\pm}| j\\ m \\pm 1 \\rangle$, for some constant $c_{jm}^{+}$, we can also obtain $$J_{\\pm}| j\\ m \\rangle = \\hbar\\sqrt{ (j \\mp m)(j \\pm m + 1) }| j\\ m\\pm 1 \\rangle.$$ Orbital angular momentumIn classical physics, orbital angular momentum is given by $\\boldsymbol{L} = \\boldsymbol{x}\\times \\boldsymbol{p}$. However, we defined $\\boldsymbol{J}$ to be the generator of an infinitesimal rotation. We can therefore ask whether the cross product definition of $\\boldsymbol{L}$ is consistent with this. First, recall the infinitesimal translation operator $$\\mathscr{J}(d\\boldsymbol{x}’) = 1 - \\frac{i\\boldsymbol{p}\\cdot d\\boldsymbol{x}’}{\\hbar},$$ which acts on a ket as follows: $\\mathscr{J}(d\\boldsymbol{x}’)| \\boldsymbol{x}’ \\rangle = | \\boldsymbol{x}’ + d\\boldsymbol{x}’ \\rangle$. This is useful because we can write $$\\mathscr{D}_{z}(d\\phi) = 1 - \\frac{iL_{z}d\\phi}{\\hbar} = 1 - \\frac{i(xp_{y} - yp_{x})d\\phi}{\\hbar} = 1 - \\frac{i\\boldsymbol{p}\\cdot d\\boldsymbol{x}’}{\\hbar},$$ with $d\\boldsymbol{x}’ = (-y’d\\phi\\quad x’d\\phi\\quad 0)^T$. In other words, we know how $\\mathscr{J}(d\\boldsymbol{x}’)$ acts on kets, so we can use this reformulation to see how $\\mathscr{D}_{z}(d\\phi)$ acts on kets when $\\boldsymbol{L}$ is defined in terms of $\\boldsymbol{x}$ and $\\boldsymbol{p}$. For an arbitrary position eigenket, we have $$\\mathscr{D}_{z}(d\\phi)| x’, y’, z’ \\rangle = | x’ - y’d\\phi, y’ + x’d\\phi, z’ \\rangle.$$ This is how we would expect the components of the position vector to transform under an infinitesimal rotation $R_{z}(d\\phi)$, so the classical definition of $\\boldsymbol{L}$ indeed generates a rotation in the sense of our earlier definition. The arguments of the wave function for a general ket $| \\psi \\rangle$ change oppositely to how the eigenvalues do, namely $$\\langle x’, y’, z’ | \\mathscr{D}_{z}(d\\phi) | \\psi \\rangle = \\langle x’ + y’d\\phi, y’ - x’d\\phi, z’ | \\psi \\rangle.$$ (Intuitively, if we rotate the system by $\\phi$, this is equivalent to rotating the argument of the wave function by $-\\phi$.) In spherical coordinates, we have $$\\langle r, \\theta, \\phi | \\mathscr{D}_{z}(d\\phi) | \\psi \\rangle = \\langle r, \\theta, \\phi - d\\phi | \\psi \\rangle = \\langle r, \\theta, \\phi | \\psi \\rangle - d\\phi\\frac{\\partial}{\\partial \\phi}\\langle r, \\theta, \\phi | \\psi \\rangle.$$ Here, we obtained the final equality by recognizing that $\\langle x’ + y’d\\phi, y’-x’d\\phi, z’ |$ is equivalent to $\\langle r, \\theta, \\phi - d\\phi |$ and Taylor expanding the wave function in spherical coordinates. An alternative means is to Taylor expand the wave function in Cartesian coordinates and then transform the derivatives. In any case, the result is that $$\\langle \\boldsymbol{x}’ | L_{z} | \\psi \\rangle = -i\\hbar \\frac{\\partial}{\\partial \\phi}\\langle \\boldsymbol{x}’ | \\psi \\rangle.$$ Repeating this process to determine the action of $L_{x}$ and $L_{y}$ (and thereby $L_{\\pm}$) in the position basis, one can then show that $\\langle \\boldsymbol{x}’ | \\boldsymbol{L}^{2} | \\psi \\rangle$ represents the action of the angular part of the Laplacian in spherical coordinates. Importantly, these relations can be used to derive the differential equations satisfied by the spherical harmonics. Angular momentum additionWhen we consider multiple degrees of freedom in a quantum system, e.g. the orbital and spin angular momenta of a single particle or the spin angular momenta of two particles, we can treat the base kets as belonging to a tensor product space (Note the difference between a tensor product space and a direct product space). In the case of two spin $\\frac{1}{2}$ particles, for example, $$\\left| \\frac{1}{2}\\ \\frac{1}{2}; \\frac{1}{2}\\ \\frac{-1}{2} \\right\\rangle = \\left| \\frac{1}{2}\\ \\frac{1}{2} \\right\\rangle\\otimes\\left| \\frac{1}{2}\\ \\frac{-1}{2} \\right\\rangle,$$ where we’ve used the naming convention $| j_{1}\\ j_{2}; m_{1}\\ m_{2} \\rangle = | j_{1}\\ m_{1} \\rangle\\otimes| j_{2}\\ m_{2} \\rangle$. Formally, consider two angular momentum operators $\\boldsymbol{J}_{1}$ and $\\boldsymbol{J}_{2}$ that operate in different subspaces of the tensor product space. The total angular momentum operator is defined as $$\\boldsymbol{J} = \\boldsymbol{J}_{1}\\otimes 1 + 1\\otimes \\boldsymbol{J}_{2}.$$ The product notation here reflects the fact that $\\boldsymbol{J}_{1}$ and $\\boldsymbol{J}_{2}$ only affect their respective subspaces. A consequence of this is that $\\boldsymbol{J}$ satisfies the fundamental angular momentum commutation relations. The key observation surrounding angular momentum addition is that there are two choices for the base kets: Eigenkets of… $| j_{1}\\ j_{2}; m_{1}\\ m_{2} \\rangle$ $\\boldsymbol{J}_{1}^{2}, \\boldsymbol{J}_{2}^{2}, J_{1z}, J_{2z}$ $| j_{1}\\ j_{2}; j\\ m \\rangle$ $\\boldsymbol{J}_{1}^{2}, \\boldsymbol{J}_{2}^{2}, \\boldsymbol{J}^{2}, J_{z}$ These particular combinations arise because we want a maximal set of compatible observables, but $[\\boldsymbol{J}^{2}, J_{1z}] \\neq 0$ and $[\\boldsymbol{J}^{2}, J_{2z}] \\neq 0$. Aside on basis transformationsThe eigenkets $| j_{1}\\ j_{2};m_{1}\\ m_{2} \\rangle$ and $| j_{1}\\ j_{2};j\\ m \\rangle$ are related by a change of basis. Even though the mathematics consists of standard manipulations from linear algebra, I think it’s easy to get caught up in the notation when seeing this for the first time in the quantum mechanics context. So, here are the basic ideas using vectors with simple labels. Recall that a unitary operator $U$ that transforms an orthonormal basis ${ | a_{i} \\rangle }$ to a new orthonormal basis ${ | b_{i} \\rangle }$, in the sense that $| b_{i} \\rangle = U| a_{i} \\rangle$, is $$U = \\sum_{i}| b_{i} \\rangle \\langle a_{i} |. \\tag{Change of basis operator}$$ The matrix representation of $U$, called the transformation matrix, is given by $\\langle a_{i} | U | a_{j} \\rangle = \\langle a_{i} | b_{j} \\rangle$. While the base kets transform via $U$, the expansion coefficients (the components of a column matrix) transform via $U^{\\dagger}$: $$\\begin{align}\\langle b_{j} | \\psi \\rangle &amp;= \\sum_{i}\\langle b_{j} | a_{i} \\rangle \\langle a_{i} | \\psi \\rangle \\\\&amp;= \\sum_{i}\\langle a_{j} | U^{\\dagger} | a_{i} \\rangle \\langle a_{i} | \\psi \\rangle.\\end{align} \\tag{Coefficient transform}$$ We also have $$| b_{j} \\rangle = \\sum_{i}| a_{i} \\rangle \\langle a_{i} | b_{j} \\rangle = \\sum_{i}| a_{i} \\rangle\\langle a_{i} | U | a_{j} \\rangle. \\tag{Base ket expansion}$$ The point I want to make is that the operator $U$ and its matrix representation appear in slightly different forms depending on the relationship being expressed (I’ve labeled the above equations to underscore this). In summary We can form the ket $| b_{j} \\rangle$ by applying the operator $U$ to $| a_{j} \\rangle$. We can obtain the components of a general ket using the matrix representation of $U^{\\dagger}$. We can expand $| b_{j} \\rangle$ as a linear combination of ${ | a_{i} \\rangle }$, where the components of the matrix representation of $U$ are the coefficients in the expansion. I realize this is a bit pedantic, but it can save confusion when the term “transformation matrix” is used loosely. Back to angular momentum additionThe eigenkets $| j_{1}\\ j_{2};m_{1}\\ m_{2} \\rangle$ and $| j_{1}\\ j_{2};j\\ m \\rangle$ are two choices for the ket space of fixed $j_{1}$ and $j_{2}$. It’s worth pausing on this statement. In general, the tensor product notation $| j_{1}\\ m_{1} \\rangle\\otimes| j_{2}\\ m_{2} \\rangle$ could be taken to mean all combinations of $j_{1}$ and $j_{2}$, but often these are understood to be fixed (For instance, if one is considering the combined spin angular momenta of two particles, the spins of the particles are fixed). In this case, then, what we are really talking about is a subspace of the tensor product space $| j_{1}\\ m_{1} \\rangle\\otimes| j_{2}\\ m_{2} \\rangle$. The identity operator in this subspace is $$\\sum_{m_{1}}\\sum_{m_{2}}| j_{1}\\ j_{2};m_{1}\\ m_{2} \\rangle \\langle j_{1}\\ j_{2};m_{1}\\ m_{2} | = 1.$$ Using this to form the base ket expansion I showed in the above aside, we can write $$| j_{1}\\ j_{2};j\\ m \\rangle = \\sum_{m_{1}}\\sum_{m_{2}}| j_{1}\\ j_{2};m_{1}\\ m_{2} \\rangle \\langle j_{1}\\ j_{2};m_{1}\\ m_{2} | j_{1}\\ j_{2};j\\ m \\rangle,$$ where $\\langle j_{1}\\ j_{2};m_{1}\\ m_{2} | j_{1}\\ j_{2};j\\ m \\rangle$ are the important Clebsch-Gordon coefficients. One can show the key properties that $\\langle j_{1}\\ j_{2};m_{1}\\ m_{2} | j_{1}\\ j_{2};j\\ m \\rangle = 0$ unless $m_{1} + m_{2} = m$ $|j_{1} - j_{2}| \\le j \\le j_{1} + j_{2}$ Since $\\langle j_{1}\\ j_{2};m_{1}\\ m_{2} | j_{1}\\ j_{2};j\\ m \\rangle$ are the elements of a unitary change of basis operator, the Clebsch-Gordon coefficients form a unitary matrix. We take the matrix elements to be real. The connection between group theory and the choice of bets kets is that the tensor product $\\mathscr{D}^{(j_{1})}\\otimes \\mathscr{D}^{(j_{2})}$ is reducible: $$\\mathscr{D}^{(j_{1})}\\otimes \\mathscr{D}^{(j_{2})} = \\mathscr{D}^{(j_{1} + j_{2})} \\oplus \\mathscr{D}^{(j_{1}+j_{2}-1)}\\oplus \\cdots\\oplus \\mathscr{D}^{(|j_{1}-j_{2}|)}.$$ In the $| j_{1}\\ j_{2};m_{1}\\ m_{2} \\rangle$ basis, the elements of the total rotation matrix $\\mathscr{D}(R) = \\mathscr{D}^{(j_{1})}(R)\\otimes \\mathscr{D}^{(j_{2})}(R)$ are given by $$\\mathscr{D}_{m_{1}’m_{1}}^{(j_{1})}(R)\\mathscr{D}_{m_{2}’m_{2}}^{(j_{2})}(R) = \\sum_{j}\\sum_{m}\\sum_{m’}\\langle j_{1}\\ j_{2};m_{1}’\\ m_{2}’ | j_{1}\\ j_{2};j\\ m’ \\rangle\\mathscr{D}_{m’m}^{(j)}(R)\\langle j_{1}\\ j_{2};m_{1}\\ m_{2} | j_{1}\\ j_{2};j\\ m \\rangle,$$ which is called the Clebsch-Gordon series. We can obtain this by expanding $\\langle j_{1}\\ j_{2};m_{1}’\\ m_{2}’ | \\mathscr{D}(R) | j_{1}\\ j_{2};m_{1}\\ m_{2} \\rangle$ two different ways. To get the left side, we use the fact that $$\\langle \\psi_{A}\\otimes \\psi_{B} | A\\otimes B | \\phi_{A}\\otimes\\phi_{B} \\rangle = \\langle \\psi_{A} | A | \\phi_{A} \\rangle \\cdot \\langle \\psi_{B} | B | \\phi_{B} \\rangle$$ for a tensor product space $\\mathcal{H} = \\mathcal{H}_{A}\\otimes\\mathcal{H}_{B}$. To get the right, we simply insert two resolutions of the identity operator in the $| j_{1}\\ j_{2};j\\ m \\rangle$ basis. In the $| j_{1}\\ j_{2};j\\ m \\rangle$ basis, the total rotation matrix $\\mathscr{D}(R)$ is block diagonal, with the block for a given $j$ simply given by $\\mathscr{D}_{m’m}^{(j)}(R)$. Each subspace of definite $j$ is irreducible. With these preliminaries about rotations and angular momentum in place, we’re in a position to introduce spherical tensors and establish physical intuition for how they’re combined via the Clebsch-Gordon tensor product.","link":"/blog/2025/02/10/angular/"},{"title":"Welcome","text":"I’m a second-year Applied Mathematics Ph.D. student at Harvard University. I’m broadly interested in AI for scientific applications, with a focus on geometric deep learning methods for turbulent flow modeling. I’m lucky to be a member of the Computational Science and Engineering Lab, led by Dr. Petros Koumoutsakos. The goal of this blog is simply to share notes on topics I’m learning about or find useful. I hope it’s a nice way to practice my technical writing, and I’d like to have a reference of the way I’ve personally come to understand different ideas. I don’t intend to suggest that I’m an expert in the material I discuss. In this spirit, I try to openly point out areas where I still have questions or an incomplete understanding, both to keep track of these places myself and to invite others to contribute any answers, comments, or insights they may have. I’m appreciative of anyone who takes the time to read my posts or reach out. I look forward to writing!","link":"/blog/2023/09/10/welcome/"}],"tags":[{"name":"Quantum mechanics","slug":"Quantum-mechanics","link":"/blog/tags/Quantum-mechanics/"}],"categories":[],"pages":[]}